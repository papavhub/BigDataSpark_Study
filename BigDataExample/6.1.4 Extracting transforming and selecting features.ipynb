{"cells":[{"cell_type":"markdown","source":["# Extracting, transforming and selecting features\n\nThis section covers algorithms for working with features, roughly divided into these groups:\n\n* (partially) Extraction: Extracting features from “raw” data\n* (partially) Transformation: Scaling, converting, or modifying features\n* (skip)Selection: Selecting a subset from a larger set of features\n* (skip)Locality Sensitive Hashing (LSH): This class of algorithms combines aspects of feature transformation with other algorithms. \n\n## Feature Extractors\n### TF-IDF (Term frequency-inverse document frequency (TF-IDF)\n* a feature vectorization method widely used in text mining to reflect the importance of a term to a document in the corpus. \n* Terminologies \n   + t: a term or a phrase\n   + d: a document \n   + D: the corpus by D\n* Term frequency TF(t,d) = the number of times that term t appears in document d\n   + (참고) https://en.wikipedia.org/wiki/Tf%E2%80%93idf\n   + 다른 정의\n      - the raw count itself: tf(t,d) = ft,d\n      - Boolean \"frequencies\": tf(t,d) = 1 if t occurs in d and 0 otherwise;\n      - term frequency adjusted for document length: tf(t,d) = ft,d ÷ (number of words in d)\n      - logarithmically scaled frequency: tf(t,d) = log (1 + ft,d);\n      - augmented frequency, to prevent a bias towards longer documents, e.g. raw frequency divided by the raw frequency of the most frequently occurring term in the document:  \n* Document frequency DF(t,D): the number of documents that contains term t. \n* IDF(t,D) = log ( (|D| +1) / (DF(t,D) +1) ) \n   + |D| the total number of documents in the corpus.\n   + DF(t,D)의 반비례(역수)를 쓰는 이유: 너무 빈번하게 모든 문서에 등장하는 단어(a, the, is 등)을 배제하기 위함 \n   + +1의 의미: 분모가 0가 되는 것을 방지하기 위함. \n\n* TFIDF(t,d,D)=TF(t,d)⋅IDF(t,D) \n\n#### TF: Both HashingTF and CountVectorizer can be used to generate the term frequency vectors.\n* HashingTF is a Transformer which takes sets of terms and converts those sets into fixed-length feature vectors. \n* CountVectorizer converts text documents to vectors of term counts. Refer to CountVectorizer for more details.\n\n#### IDF\n* IDF is an Estimator which is fit on a dataset and produces an IDFModel. \n* The IDFModel takes feature vectors (generally created from HashingTF or CountVectorizer) and scales each feature. Intuitively, it down-weights features which appear frequently in a corpus."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0bba09b5-dcbb-4d9b-862b-8c7cd8d18f19"}}},{"cell_type":"code","source":["from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n\nsentenceData = spark.createDataFrame([\n    (0.0, \"Hi I heard about Spark\"),\n    (0.0, \"I wish Java could use case classes\"),\n    (1.0, \"Logistic regression models are neat\")\n], [\"label\", \"sentence\"])\n\ntokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\nwordsData = tokenizer.transform(sentenceData)\nwordsData.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"05b82f59-9845-4e96-94a8-25bbb2066b76"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-----+--------------------+--------------------+\n|label|            sentence|               words|\n+-----+--------------------+--------------------+\n|  0.0|Hi I heard about ...|[hi, i, heard, ab...|\n|  0.0|I wish Java could...|[i, wish, java, c...|\n|  1.0|Logistic regressi...|[logistic, regres...|\n+-----+--------------------+--------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----+--------------------+--------------------+\n|label|            sentence|               words|\n+-----+--------------------+--------------------+\n|  0.0|Hi I heard about ...|[hi, i, heard, ab...|\n|  0.0|I wish Java could...|[i, wish, java, c...|\n|  1.0|Logistic regressi...|[logistic, regres...|\n+-----+--------------------+--------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=20)\nfeaturizedData = hashingTF.transform(wordsData)\nfeaturizedData.show()\n# alternatively, CountVectorizer can also be used to get term frequency vectors\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4d0fa6d8-32ed-4367-ba0c-346250d72ce7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-----+--------------------+--------------------+--------------------+\n|label|            sentence|               words|         rawFeatures|\n+-----+--------------------+--------------------+--------------------+\n|  0.0|Hi I heard about ...|[hi, i, heard, ab...|(20,[6,8,13,16],[...|\n|  0.0|I wish Java could...|[i, wish, java, c...|(20,[0,2,7,13,15,...|\n|  1.0|Logistic regressi...|[logistic, regres...|(20,[3,4,6,11,19]...|\n+-----+--------------------+--------------------+--------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----+--------------------+--------------------+--------------------+\n|label|            sentence|               words|         rawFeatures|\n+-----+--------------------+--------------------+--------------------+\n|  0.0|Hi I heard about ...|[hi, i, heard, ab...|(20,[6,8,13,16],[...|\n|  0.0|I wish Java could...|[i, wish, java, c...|(20,[0,2,7,13,15,...|\n|  1.0|Logistic regressi...|[logistic, regres...|(20,[3,4,6,11,19]...|\n+-----+--------------------+--------------------+--------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\nidfModel = idf.fit(featurizedData)\nrescaledData = idfModel.transform(featurizedData)\n\nrescaledData.select(\"label\", \"features\").show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f849084b-ab2c-4c6e-82f4-63dc6b4eed6d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-----+--------------------+\n|label|            features|\n+-----+--------------------+\n|  0.0|(20,[6,8,13,16],[...|\n|  0.0|(20,[0,2,7,13,15,...|\n|  1.0|(20,[3,4,6,11,19]...|\n+-----+--------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----+--------------------+\n|label|            features|\n+-----+--------------------+\n|  0.0|(20,[6,8,13,16],[...|\n|  0.0|(20,[0,2,7,13,15,...|\n|  1.0|(20,[3,4,6,11,19]...|\n+-----+--------------------+\n\n"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"6.1.4 Extracting, transforming and selecting features","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":1734125070039839}},"nbformat":4,"nbformat_minor":0}
